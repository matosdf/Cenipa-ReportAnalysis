{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURA√á√ïES\n",
    "# ==============================================================================\n",
    "\n",
    "# Diret√≥rio onde est√£o os JSONs de TREINO (Excluindo o holdout set)\n",
    "TREINO_DIR = Path('data/json/llm_ready')\n",
    "\n",
    "# Arquivo para salvar o √≠ndice de embeddings (Numpy array e a lista de fatores)\n",
    "INDICE_PATH = Path('data/fewshot_index.json')\n",
    "\n",
    "# ==============================================================================\n",
    "# FUN√á√ïES DE PROCESSAMENTO\n",
    "# ==============================================================================\n",
    "\n",
    "def criar_indice_tfidf(treino_dir: Path) -> Tuple[Any, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Cria um √≠ndice baseado em TF-IDF (simula√ß√£o do Embedding) e coleta dados.\n",
    "    \"\"\"\n",
    "    documentos = []\n",
    "    metadata = []\n",
    "    arquivos_json = list(treino_dir.glob(\"*.json\"))\n",
    "\n",
    "    print(f\"üìÅ Preparando para indexar {len(arquivos_json)} documentos de treino...\")\n",
    "\n",
    "    for arquivo_path in arquivos_json:\n",
    "        try:\n",
    "            with open(arquivo_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Concatena Historico e Analise para criar o documento (contexto)\n",
    "            historico = data.get('conteudo', {}).get('historico_voo', '')\n",
    "            analise = data.get('conteudo', {}).get('analise', '')\n",
    "            texto_contexto = historico + \" \" + analise\n",
    "\n",
    "            fatores = data.get('conteudo', {}).get('fatores_contribuintes', [])\n",
    "\n",
    "            if len(fatores) > 0 and len(texto_contexto) > 50:\n",
    "                documentos.append(texto_contexto)\n",
    "                # Armazena o JSON original, o texto de contexto e a lista de fatores\n",
    "                metadata.append({\n",
    "                    'arquivo': arquivo_path.name,\n",
    "                    'contexto': texto_contexto,\n",
    "                    'fatores': fatores\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Erro ao ler ou analisar {arquivo_path.name}: {e}\")\n",
    "\n",
    "    if not documentos:\n",
    "        print(\"üõë Nenhum documento v√°lido para indexa√ß√£o. Verifique a pasta.\")\n",
    "        return None, []\n",
    "\n",
    "    # Inicializa e treina o TF-IDF Vectorizer\n",
    "    # O TF-IDF serve como um substituto simples para embeddings, capturando import√¢ncia das palavras\n",
    "    # Use stop_words='portuguese' para remover preposi√ß√µes comuns, pois aqui queremos o \"conte√∫do\"\n",
    "    # Lembre-se: idealmente, este passo usaria Sentence-Transformers, mas TF-IDF √© Zero-Dependency\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=5, # M√≠nimo de 5 documentos para uma palavra ser relevante\n",
    "        max_features=10000,\n",
    "        stop_words=None # MANTEM AS STOPWORDS para a busca sem√¢ntica do LLM.\n",
    "    )\n",
    "\n",
    "    # Cria o √≠ndice (matriz esparsa de vetores)\n",
    "    tfidf_matrix = vectorizer.fit_transform(documentos)\n",
    "\n",
    "    print(f\"‚úÖ Indexa√ß√£o TF-IDF conclu√≠da. Total de vetores: {tfidf_matrix.shape[0]}\")\n",
    "\n",
    "    return vectorizer, tfidf_matrix, metadata\n",
    "\n",
    "def salvar_indice(vectorizer, tfidf_matrix, metadata: List[Dict[str, Any]], indice_path: Path):\n",
    "    \"\"\"\n",
    "    Salva os componentes do √≠ndice em um arquivo JSON para facilitar o uso no Few-Shot.\n",
    "    Nota: Salvar o vetorizador e a matriz TF-IDF completa √© complexo em JSON,\n",
    "    ent√£o vamos salvar apenas a metadata e a fun√ß√£o de sele√ß√£o ser√° implementada em tempo real\n",
    "    no script Few-Shot.\n",
    "    \"\"\"\n",
    "    # Simplifica√ß√£o: Apenas salvar o metadata.\n",
    "    # O Few-Shot script ter√° que refazer o TFIDF, ou o usu√°rio deve salvar os objetos\n",
    "    # Python serializados (pickle), o que n√£o √© recomendado em produ√ß√£o.\n",
    "\n",
    "    # Para fins de demonstra√ß√£o, vamos apenas salvar a metadata para o pr√≥ximo script carregar.\n",
    "    # Em um ambiente real, o Vectorizer e a Matriz seriam serializados (com pickle/joblib)\n",
    "    # ou persistidos em um banco de dados vetorial.\n",
    "\n",
    "    # Aqui, apenas salvamos os documentos de contexto e seus fatores (os 'r√≥tulos')\n",
    "    with open(indice_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"üíæ Metadata de treino salva em: {indice_path}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECU√á√ÉO PRINCIPAL\n",
    "# ==============================================================================\n",
    "\n",
    "def main_indexador():\n",
    "    if not TREINO_DIR.exists():\n",
    "        print(f\"Diret√≥rio de treino n√£o encontrado: {TREINO_DIR}\")\n",
    "        return\n",
    "\n",
    "    # 1. Criar o √≠ndice (matriz TFIDF e metadados)\n",
    "    vectorizer, tfidf_matrix, metadata = criar_indice_tfidf(TREINO_DIR)\n",
    "\n",
    "    if metadata:\n",
    "        # 2. Salvar os resultados (apenas metadata para evitar depend√™ncias complexas)\n",
    "        # O pr√≥ximo script (fewshot_generator.py) ir√° refazer a matriz TFIDF,\n",
    "        # o que √© aceit√°vel para um pequeno conjunto de treino.\n",
    "        salvar_indice(vectorizer, tfidf_matrix, metadata, INDICE_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_indexador()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
