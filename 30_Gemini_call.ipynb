{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T13:12:16.865391Z",
     "start_time": "2025-11-21T13:10:55.431755Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- IMPORTA√á√ÉO DA SDK (google-genai) ---\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURA√á√ïES GERAIS\n",
    "# ==============================================================================\n",
    "\n",
    "# Carrega vari√°veis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# 1. Configura√ß√£o da API Key\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# 2. Configura√ß√£o do Modelo\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "# 3. Configura√ß√£o de Gera√ß√£o Padr√£o\n",
    "GENERATION_CONFIG = types.GenerateContentConfig(\n",
    "    temperature=0.2,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    #max_output_tokens=1000,\n",
    "    response_mime_type=\"text/plain\",\n",
    "    safety_settings=[\n",
    "        types.SafetySetting(\n",
    "            category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "            threshold=\"BLOCK_NONE\"\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "            threshold=\"BLOCK_NONE\"\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "            threshold=\"BLOCK_NONE\"\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "            threshold=\"BLOCK_NONE\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Configura√ß√£o de Amostragem e Logs\n",
    "QTDE_AMOSTRA_TESTE = 1  # Mantido conforme seu notebook\n",
    "\n",
    "# Caminhos (Ajustados conforme seu notebook)\n",
    "INPUT_DIR = Path('data/json/test_ready')\n",
    "FEW_SHOT_DIR = Path('data/json/fewshot_samples')\n",
    "OUTPUT_FILE = Path('results/cenipa_gemini_results.json')\n",
    "LOG_FILE = Path('logs/log_execucao_arquivos.csv')\n",
    "\n",
    "# ==============================================================================\n",
    "# TAXONOMIA CENIPA (Do seu arquivo base)\n",
    "# ==============================================================================\n",
    "TAXONOMIA_CENIPA = {\n",
    "    \"Fatores Humanos\": [\n",
    "        \"√Ålcool\", \"Ansiedade\", \"Aten√ß√£o\", \"Atitude\", \"Capacita√ß√£o e treinamento\",  \"Caracter√≠sticas da tarefa\", \"Clima organizacional\",\n",
    "        \"Comunica√ß√£o\", \"Condi√ß√µes f√≠sicas do trabalho\", \"Cultura do grupo de trabalho\", \"Cultura organizacional\", \"Desorienta√ß√£o\", \"Dieta inadequada\",\n",
    "        \"Din√¢mica da equipe\", \"Disbarismo\", \"Dor\", \"Enfermidade\", \"Enjoo a√©reo\", \"Equipamento - caracter√≠sticas ergon√¥micas\", \"Estado emocional\", \"Fadiga\",\n",
    "        \"Gravidez\", \"Hiperventila√ß√£o\", \"Hip√≥xia\", \"Ilus√µes visuais\", \"Inconsci√™ncia\", \"Influ√™ncias externas\", \"Ins√¥nia\", \"Intoxica√ß√£o alimentar\",\n",
    "        \"Intoxica√ß√£o por CO\", \"Mem√≥ria\", \"Motiva√ß√£o\", \"Obesidade\", \"Organiza√ß√£o do trabalho\", \"Percep√ß√£o\", \"Processo decis√≥rio\", \"Processos Organizacionais\",\n",
    "        \"Pr√≥teses\", \"Rela√ß√µes interpessoais\", \"Ressaca\", \"Sistemas de apoio\", \"Sobrecarga de tarefas\", \"Uso de Medicamento\", \"Uso il√≠cito de drogas\", \"Vertigem\",\n",
    "        \"Vestimenta inadequada\"\n",
    "    ],\n",
    "    \"Fatores Operacionais\": [\n",
    "        \"Aplica√ß√£o do comando\", \"Condi√ß√µes meteorol√≥gicas adversas\", \"Conhecimento de normas (ATS)\", \"Console (ATS)\", \"Coordena√ß√£o de cabine\",\n",
    "        \"Coordena√ß√£o de tr√°fego (ATS)\", \"Desvio de navega√ß√£o\", \"Emprego de meios (ATS)\", \"Equipamento de apoio (ATS)\", \"Fraseologia da tripula√ß√£o\",\n",
    "        \"Fraseologia do √ìrg√£o ATS\", \"Habilidade de controle (ATS)\", \"Indisciplina de voo\", \"Infraestrutura aeroportu√°ria\", \"Instru√ß√£o\",\n",
    "        \"Julgamento de pilotagem\", \"Limite de autoriza√ß√£o\", \"Manuten√ß√£o da aeronave\", \"Outro\", \"Pessoal de apoio\", \"Planejamento de tr√°fego (ATS)\",\n",
    "        \"Planejamento do voo\", \"Planejamento gerencial\", \"Pouca experi√™ncia do piloto\", \"Presen√ßa de ave\", \"Presen√ßa de fauna (n√£o ave)\", \"Publica√ß√µes (ATS)\",\n",
    "        \"RADAR (ATS)\", \"Servi√ßo fixo (ATS)\", \"Servi√ßo m√≥vel (ATS)\", \"Substitui√ß√£o na posi√ß√£o (ATS)\", \"Supervis√£o (ATS)\", \"Supervis√£o gerencial\",\n",
    "        \"Tratamento (ATS)\", \"Visualiza√ß√£o (ATS)\"\n",
    "    ],\n",
    "    \"Fatores Materiais\": [\n",
    "        \"Fabrica√ß√£o\", \"Manuseio do material\", \"Projeto\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "TODOS_FATORES = []\n",
    "for cat in TAXONOMIA_CENIPA.values():\n",
    "    TODOS_FATORES.extend(cat)\n",
    "\n",
    "# ==============================================================================\n",
    "# FUN√á√ïES DE UTILIDADE\n",
    "# ==============================================================================\n",
    "\n",
    "def get_gemini_client():\n",
    "    if not API_KEY:\n",
    "        print(\"‚ö†Ô∏è ERRO: API Key n√£o encontrada.\")\n",
    "        return None\n",
    "    return genai.Client(api_key=API_KEY)\n",
    "\n",
    "def carregar_relatorios(diretorio: Path) -> List[Dict]:\n",
    "    relatorios = []\n",
    "    if not diretorio.exists():\n",
    "        print(f\"‚ö†Ô∏è Diret√≥rio n√£o encontrado: {diretorio}\")\n",
    "        return []\n",
    "\n",
    "    arquivos = list(diretorio.glob(\"*.json\"))\n",
    "    if not arquivos:\n",
    "        print(f\"‚ö†Ô∏è Nenhum arquivo JSON encontrado em: {diretorio}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Carregando {len(arquivos)} arquivos de treino de: {diretorio}...\")\n",
    "    for arquivo in arquivos:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                data['filename'] = arquivo.name\n",
    "                if 'conteudo' in data:\n",
    "                    relatorios.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"  Erro ao ler {arquivo.name}: {e}\")\n",
    "    return relatorios\n",
    "\n",
    "def salvar_log_csv(relatorios_selecionados: List[Dict]):\n",
    "    # Garante que a pasta logs existe\n",
    "    LOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"üìù Salvando log dos arquivos selecionados em: {LOG_FILE}\")\n",
    "\n",
    "    with open(LOG_FILE, mode='w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Data_Hora', 'Arquivo_Selecionado'])\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        for relatorio in relatorios_selecionados:\n",
    "            writer.writerow([timestamp, relatorio['filename']])\n",
    "\n",
    "def preparar_texto_relatorio(conteudo_json: Dict) -> str:\n",
    "    historico = conteudo_json.get('historico_voo', '')\n",
    "    analise = conteudo_json.get('analise', '')\n",
    "    return f\"\"\"\n",
    "    --- IN√çCIO DO RELAT√ìRIO ---\n",
    "    HIST√ìRICO DO VOO:\n",
    "    {historico}\n",
    "\n",
    "    AN√ÅLISE:\n",
    "    {analise}\n",
    "    --- FIM DO RELAT√ìRIO ---\n",
    "    \"\"\"\n",
    "\n",
    "def chamar_gemini(client, prompt: str, retries=3, custom_config=None) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper com DEBUG DE SEGURAN√áA/BLOQUEIO.\n",
    "    Se a resposta vier vazia, investiga se foi Safety, Recitation ou Outro.\n",
    "    \"\"\"\n",
    "    config_to_use = custom_config if custom_config else GENERATION_CONFIG\n",
    "\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_NAME,\n",
    "                contents=prompt,\n",
    "                config=config_to_use\n",
    "            )\n",
    "\n",
    "            # Se tiver texto, sucesso!\n",
    "            if response.text:\n",
    "                return response.text\n",
    "\n",
    "            # --- DEBUG: Investigando Bloqueio ---\n",
    "            print(f\"  ‚ö†Ô∏è AVISO: Resposta vazia (Tentativa {i+1}). Investigando motivo...\")\n",
    "\n",
    "            if response.candidates:\n",
    "                candidate = response.candidates[0]\n",
    "                reason = candidate.finish_reason\n",
    "                print(f\"     -> Motivo do Bloqueio (Finish Reason): {reason}\")\n",
    "\n",
    "                # Se for seguran√ßa, detalha qual filtro\n",
    "                if reason == \"SAFETY\":\n",
    "                    for r in candidate.safety_ratings:\n",
    "                        # Mostra apenas os que n√£o s√£o NEGLIGIBLE para n√£o poluir\n",
    "                        if r.probability != \"NEGLIGIBLE\":\n",
    "                            print(f\"     -> Filtro Ativado: {r.category} | Probabilidade: {r.probability}\")\n",
    "                elif reason == \"RECITATION\":\n",
    "                    print(\"     -> Bloqueio por Recita√ß√£o (Copyright/Pl√°gio de texto existente).\")\n",
    "                elif reason == \"OTHER\":\n",
    "                    print(\"     -> Bloqueio 'OTHER'. Pode ser idioma ou filtro interno n√£o especificado.\")\n",
    "            else:\n",
    "                print(\"     -> Nenhum candidato retornado pela API (Erro desconhecido).\")\n",
    "\n",
    "            return \"BLOQUEADO_PELO_FILTRO\"\n",
    "\n",
    "        except Exception as e:\n",
    "            wait_time = 10 * (i + 1)\n",
    "            msg_erro = str(e)\n",
    "            if \"429\" in msg_erro or \"RESOURCE_EXHAUSTED\" in msg_erro:\n",
    "                print(f\"  ‚ö†Ô∏è COTA EXCEDIDA (429). Aguardando {wait_time}s...\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Erro na API (tentativa {i+1}/{retries}): {e}. Aguardando {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    return \"ERRO_API\"\n",
    "\n",
    "# ==============================================================================\n",
    "# ESTRAT√âGIAS DE PROMPT\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Zero Shot\n",
    "def estrategia_zero_shot(client, texto_relatorio: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Voc√™ √© um especialista em seguran√ßa de voo (CENIPA).\n",
    "    Leia o relat√≥rio abaixo e liste APENAS os Fatores Contribuintes.\n",
    "    SEJA CONCISO. N√£o escreva introdu√ß√µes ou justificativas. Apenas os nomes dos fatores separados por v√≠rgula.\n",
    "\n",
    "    {texto_relatorio}\n",
    "\n",
    "    Fatores Contribuintes:\n",
    "    \"\"\"\n",
    "    return chamar_gemini(client, prompt)\n",
    "\n",
    "# 2. Few Shot\n",
    "def estrategia_few_shot(client, texto_relatorio: str, exemplos: List[Dict]) -> str:\n",
    "    prompt_exemplos = \"\"\n",
    "    for ex in exemplos:\n",
    "        txt_ex = preparar_texto_relatorio(ex['conteudo'])\n",
    "        fatores_ex = \", \".join(ex['conteudo'].get('fatores_contribuintes', []))\n",
    "        prompt_exemplos += f\"\"\"\n",
    "        Exemplo de Relat√≥rio:\n",
    "        {txt_ex}\n",
    "        Fatores Contribuintes Identificados:\n",
    "        {fatores_ex}\n",
    "        -----------------------------------\n",
    "        \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Voc√™ √© um especialista CENIPA. Extraia os fatores contribuintes. Siga o padr√£o dos exemplos (apenas a lista).\n",
    "\n",
    "    {prompt_exemplos}\n",
    "\n",
    "    Novo Relat√≥rio:\n",
    "    {texto_relatorio}\n",
    "\n",
    "    Resposta (Apenas Fatores):\n",
    "    \"\"\"\n",
    "    return chamar_gemini(client, prompt)\n",
    "\n",
    "# 3. Auto-CoT\n",
    "def estrategia_auto_cot(client, texto_relatorio: str) -> str:\n",
    "    cot_config = types.GenerateContentConfig(\n",
    "        temperature=0.2,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "        #max_output_tokens=1000,\n",
    "        safety_settings=GENERATION_CONFIG.safety_settings\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "    Voc√™ √© um investigador de acidentes a√©reos.\n",
    "    Leia o relat√≥rio abaixo.\n",
    "\n",
    "    {texto_relatorio}\n",
    "\n",
    "    Tarefa: Identificar os fatores contribuintes.\n",
    "    Pense passo a passo nas falhas humanas, materiais e operacionais descritas no texto.\n",
    "    Raciocine sobre a causalidade.\n",
    "    No final, liste os fatores contribuintes finais.\n",
    "    \"\"\"\n",
    "    return chamar_gemini(client, prompt, custom_config=cot_config)\n",
    "\n",
    "# 4. Zero Shot+\n",
    "def estrategia_zero_shot_plus(client, texto_relatorio: str) -> str:\n",
    "    lista_fatores_str = \", \".join(TODOS_FATORES)\n",
    "    prompt = f\"\"\"\n",
    "    Analise o relat√≥rio. Selecione quais fatores da lista oficial do CENIPA contribu√≠ram.\n",
    "    Responda APENAS com os itens da lista selecionados, separados por v√≠rgula.\n",
    "\n",
    "    Lista Oficial:\n",
    "    [{lista_fatores_str}]\n",
    "\n",
    "    {texto_relatorio}\n",
    "\n",
    "    Fatores Contribuintes (apenas a lista):\n",
    "    \"\"\"\n",
    "    return chamar_gemini(client, prompt)\n",
    "\n",
    "# 5. CFG-CoT\n",
    "def estrategia_cfg_cot(client, texto_relatorio: str) -> Dict[str, str]:\n",
    "    cot_config = types.GenerateContentConfig(\n",
    "        temperature=0.2,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "        #max_output_tokens=1000,\n",
    "        safety_settings=GENERATION_CONFIG.safety_settings\n",
    "    )\n",
    "    respostas = {}\n",
    "\n",
    "    prompt_humanos = f\"\"\"\n",
    "    Analise focando EXCLUSIVAMENTE em Fatores Humanos.\n",
    "    R√≥tulos poss√≠veis: {\", \".join(TAXONOMIA_CENIPA['Fatores Humanos'])}.\n",
    "\n",
    "    {texto_relatorio}\n",
    "\n",
    "    Quais fatores humanos da lista acima est√£o presentes? Explique brevemente e liste.\n",
    "    \"\"\"\n",
    "    respostas['humanos'] = chamar_gemini(client, prompt_humanos, custom_config=cot_config)\n",
    "\n",
    "    prompt_operacionais = f\"\"\"\n",
    "    Analise focando EXCLUSIVAMENTE em Fatores Operacionais.\n",
    "    R√≥tulos poss√≠veis: {\", \".join(TAXONOMIA_CENIPA['Fatores Operacionais'])}.\n",
    "\n",
    "    {texto_relatorio}\n",
    "\n",
    "    Quais fatores operacionais da lista acima est√£o presentes? Explique brevemente e liste.\n",
    "    \"\"\"\n",
    "    time.sleep(2)\n",
    "    respostas['operacionais'] = chamar_gemini(client, prompt_operacionais, custom_config=cot_config)\n",
    "\n",
    "    prompt_materiais = f\"\"\"\n",
    "    Analise focando EXCLUSIVAMENTE em Fatores Materiais.\n",
    "    R√≥tulos poss√≠veis: {\", \".join(TAXONOMIA_CENIPA['Fatores Materiais'])}.\n",
    "\n",
    "    {texto_relatorio}\n",
    "\n",
    "    Quais fatores materiais da lista acima est√£o presentes? Explique brevemente e liste.\n",
    "    \"\"\"\n",
    "    time.sleep(2)\n",
    "    respostas['materiais'] = chamar_gemini(client, prompt_materiais, custom_config=cot_config)\n",
    "\n",
    "    respostas['consolidado'] = f\"HUMANOS: {respostas['humanos']}\\nOPERACIONAIS: {respostas['operacionais']}\\nMATERIAIS: {respostas['materiais']}\"\n",
    "    return respostas['consolidado']\n",
    "\n",
    "# ==============================================================================\n",
    "# LOOP PRINCIPAL\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"--- Iniciando Benchmark CENIPA vs GEMINI (V3 - Safety Debug) ---\")\n",
    "    print(f\"Configura√ß√£o: Processar {QTDE_AMOSTRA_TESTE} arquivos aleat√≥rios.\")\n",
    "\n",
    "    client = get_gemini_client()\n",
    "    if not client:\n",
    "        return\n",
    "\n",
    "    # 1. Listar e Sortear arquivos\n",
    "    print(f\"\\nListando arquivos no diret√≥rio: {INPUT_DIR}\")\n",
    "    if not INPUT_DIR.exists():\n",
    "        print(\"‚ùå ERRO: Diret√≥rio de teste n√£o encontrado.\")\n",
    "        return\n",
    "\n",
    "    todos_paths = list(INPUT_DIR.glob(\"*.json\"))\n",
    "    total_disponivel = len(todos_paths)\n",
    "    if total_disponivel == 0:\n",
    "        print(\"‚ùå ERRO: Nenhum arquivo JSON encontrado.\")\n",
    "        return\n",
    "\n",
    "    tamanho_amostra = min(QTDE_AMOSTRA_TESTE, total_disponivel)\n",
    "    paths_sorteados = random.sample(todos_paths, tamanho_amostra)\n",
    "\n",
    "    conjunto_teste = []\n",
    "    for path in paths_sorteados:\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                data['filename'] = path.name\n",
    "                if 'conteudo' in data:\n",
    "                    conjunto_teste.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"  Erro ao ler {path.name}: {e}\")\n",
    "\n",
    "    if conjunto_teste:\n",
    "        salvar_log_csv(conjunto_teste)\n",
    "    else:\n",
    "        print(\"Nenhum arquivo v√°lido carregado.\")\n",
    "        return\n",
    "\n",
    "    # 2. Carregar Dados de Treino\n",
    "    exemplos_few_shot = carregar_relatorios(FEW_SHOT_DIR)\n",
    "    if exemplos_few_shot:\n",
    "        print(f\"‚úÖ {len(exemplos_few_shot)} exemplos de Few-Shot carregados.\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Iniciando processamento de {len(conjunto_teste)} casos de teste...\")\n",
    "    resultados_finais = []\n",
    "\n",
    "    # Garante diret√≥rio de sa√≠da\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for idx, caso in enumerate(conjunto_teste):\n",
    "        nome_arq = caso.get('filename', f'caso_{idx}')\n",
    "        print(f\"\\nProcessando caso {idx+1}/{len(conjunto_teste)}: {nome_arq}\")\n",
    "\n",
    "        texto = preparar_texto_relatorio(caso['conteudo'])\n",
    "        ground_truth = caso['conteudo'].get('fatores_contribuintes', [])\n",
    "\n",
    "        res_caso = {\n",
    "            \"arquivo\": nome_arq,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"respostas\": {}\n",
    "        }\n",
    "\n",
    "        if idx > 0:\n",
    "            print(\"  (Aguardando 15s para aliviar cota entre arquivos...)\")\n",
    "            time.sleep(15)\n",
    "\n",
    "        print(\"  > Executando Zero Shot...\")\n",
    "        res_caso[\"respostas\"][\"zero_shot\"] = estrategia_zero_shot(client, texto)\n",
    "\n",
    "        print(\"  > Executando Few Shot...\")\n",
    "        if exemplos_few_shot:\n",
    "            res_caso[\"respostas\"][\"few_shot\"] = estrategia_few_shot(client, texto, exemplos_few_shot)\n",
    "        else:\n",
    "            res_caso[\"respostas\"][\"few_shot\"] = \"SKIPPED_NO_EXAMPLES\"\n",
    "\n",
    "        print(\"  > Executando Auto-CoT...\")\n",
    "        res_caso[\"respostas\"][\"auto_cot\"] = estrategia_auto_cot(client, texto)\n",
    "\n",
    "        print(\"  > Executando Zero Shot+...\")\n",
    "        res_caso[\"respostas\"][\"zero_shot_plus\"] = estrategia_zero_shot_plus(client, texto)\n",
    "\n",
    "        print(\"  > Executando CFG-CoT (3 steps)...\")\n",
    "        res_caso[\"respostas\"][\"cfg_cot\"] = estrategia_cfg_cot(client, texto)\n",
    "\n",
    "        resultados_finais.append(res_caso)\n",
    "\n",
    "    print(f\"\\nSalvando resultados em {OUTPUT_FILE}...\")\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(resultados_finais, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"Conclu√≠do com sucesso!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Benchmark CENIPA vs GEMINI (V3 - Safety Debug) ---\n",
      "Configura√ß√£o: Processar 1 arquivos aleat√≥rios.\n",
      "\n",
      "Listando arquivos no diret√≥rio: data\\json\\test_ready\n",
      "üìù Salvando log dos arquivos selecionados em: logs\\log_execucao_arquivos.csv\n",
      "Carregando 3 arquivos de treino de: data\\json\\fewshot_samples...\n",
      "‚úÖ 3 exemplos de Few-Shot carregados.\n",
      "\n",
      "‚úÖ Iniciando processamento de 1 casos de teste...\n",
      "\n",
      "Processando caso 1/1: pr_sfs_23_01_13.json\n",
      "  > Executando Zero Shot...\n",
      "  > Executando Few Shot...\n",
      "  > Executando Auto-CoT...\n",
      "  > Executando Zero Shot+...\n",
      "  > Executando CFG-CoT (3 steps)...\n",
      "\n",
      "Salvando resultados em results\\cenipa_gemini_results.json...\n",
      "Conclu√≠do com sucesso!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c42d44657a8e38f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
